{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ab72440",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import R68_MCMC_MPI as mpi #importing runs the entire script... so I can't do that here. Instead I'll just have to copy code for now.\n",
    "\n",
    "################################################################################\n",
    "#Setup\n",
    "################################################################################\n",
    "\n",
    "#we may need some code in the ../python directory and/or matplotlib styles\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../../../python/')\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")\n",
    "\n",
    "#set up matplotlib\n",
    "os.environ['MPLCONFIGDIR'] = '../../../mplstyles'\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "#got smarter about the mpl config: see mplstyles/ directory\n",
    "plt.style.use('standard')\n",
    "\n",
    "#fonts\n",
    "# Set the font dictionaries (for plot title and axis titles)\n",
    "title_font = {'fontname':'Arial', 'size':'16', 'color':'black', 'weight':'normal',\n",
    "              'verticalalignment':'bottom'} # Bottom vertical alignment for more space\n",
    "axis_font = {'fontname':'Arial', 'size':'32'}\n",
    "legend_font = {'fontname':'Arial', 'size':'22'}\n",
    "\n",
    "#fonts global settings\n",
    "mpl.rc('font',family=legend_font['fontname'])\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from constants import *\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "#For some reason, this speeds things up!\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "#Added for notebook\n",
    "import emcee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59181dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "#Fit Settings\n",
    "################################################################################\n",
    "#Construct a dictionary to store all the MCMC fit parameters and results\n",
    "#These are all the settings a user will regularly change\n",
    "\n",
    "        ########################## Data Settings ##########################\n",
    "mcmc_data={'g4_load_frac':1,\n",
    "          'cap_load_frac':1,\n",
    "          #'cap_sim_file':'/data/chocula/villaa/cascadeSimData/si28_R68_400k.pkl',\n",
    "          #'cap_rcapture':0.161,\n",
    "          'cap_sim_file':'../data/v3_400k.pkl',\n",
    "          'cap_rcapture':0.218,\n",
    "           ########################## Spectrum Settings ##########################\n",
    "          'Emax': 2000, #[eVee]\n",
    "          'Ebins': np.linspace(0,2500,251), #np.linspace(0,2000,201),\n",
    "           'Efit_min':50, #[eVee]\n",
    "           'Efit_max':2000, #1750, #[eVee]\n",
    "           'spectrum_units':'reco-rate', #One of {'counts', 'reco-rate'}\n",
    "           ########################## Yield Model Settings ##########################\n",
    "           #'Y_model':'Lind',\n",
    "           #'Y_labels': [r'k', r'$F_{NR}$'],\n",
    "           #'Y_bounds': [(0.05,0.3),(0,30)],\n",
    "           #'Y_model':'Chav',\n",
    "           #'Y_labels': [r'k', r'$a^{-1}$', r'$F_{NR}$'],\n",
    "           #'Y_bounds': [(0.05,0.3),(0,2e3),(0,30)],\n",
    "           'Y_model':'Sor',\n",
    "           'Y_labels': [r'k', r'q', r'$F_{NR}$'],\n",
    "           'Y_bounds': [(0.05,0.3),(0,3e-2),(0,30)],\n",
    "           #'Y_model':'AC',\n",
    "           #'Y_labels': [r'k', r'$\\xi$', r'$F_{NR}$'],\n",
    "           #'Y_bounds': [(0.05,0.3),(0,2e3),(0,30)],\n",
    "           #'Y_model':'pchip',\n",
    "           #'Y_labels': [r'k', 'Er0', 'Er1', 'Er2', 'f1', r'$F_{NR}$'],\n",
    "           #'Y_bounds': [(0.05,0.3),(0,1e-3),(0,1e-3),(0,1e-3),(0,1),(0,10)],\n",
    "           #'Y_model':'Shexp',\n",
    "           #'Y_labels': [r'k', 'Yshelf', 'Ec', 'dE', 'alpha', r'$F_{NR}$'],\n",
    "           #'Y_bounds': [(0.05,0.3),(0,0.3),(0,1e3),(0,1e3),(0,100),(0,30)],\n",
    "           #'Y_model':'Pol3',\n",
    "           #'Y_labels': [r'p0', r'p1', r'p2', r'$F_{NR}$'],\n",
    "           #'Y_bounds': [(-0.5,0.5),(-5e-4,5e-4),(-5e-7,5e-7),(0,30)],\n",
    "           ########################## Sim Spectra Settings ##########################\n",
    "           'ER_spec_model':'sim', #One of {'sim', 'flat') to selct from G4 simulation or flat\n",
    "           #'ER_par_labels':[r'$scale_{G4}$'],\n",
    "           'ER_par_labels':[r'$scale_{ER}$'],\n",
    "           'ER_par_bounds':[(0,20)], #Unitless scaling factor\n",
    "           #'ER_spec_model':'flat',\n",
    "           #'ER_par_labels':[r'$R0_{ER}$'],\n",
    "           #'ER_par_bounds':[(0,4e-2)], # Units are [Counts/sec/eVee bin] or [Counts/eVee bin] depending on spectrum_units\n",
    "           #\n",
    "           'NR_spec_model':'sim', #One of {'sim', 'flat', 'exp') to selct from G4 simulation, flat, or exponential\n",
    "           #'NR_par_labels':[r'$scale_{G4}$'],\n",
    "           'NR_par_labels':[r'$scale_{NR}$'],\n",
    "           'NR_par_bounds':[(0,20)], #Unitless scaling factor\n",
    "           #'NR_spec_model':'exp',\n",
    "           #'NR_par_labels':[r'$R0_{NR}$',r'$E0_{NR}$'], #R0*exp(-E/E0) gives NR spectrum (post-yield)\n",
    "           #'NR_par_bounds':[(0,0.1),(0,2e3)], # Units are [Counts/sec/eVee bin, eVee] or [Counts/eVee bin] depending on spectrum_units\n",
    "           #\n",
    "           'NG_spec_model':'sim', #Not going to implement anything other than sim for (n,gamma) yet\n",
    "           'NG_par_labels':[r'$scale_{ng}$'],\n",
    "           'NG_par_bounds':[(0,10)], #Unitless scaling factor\n",
    "           ########################## Likelihood Settings ##########################\n",
    "           'likelihood':'SNorm', #One of {'Pois', 'Norm', 'SNorm'} Only SNorm uses sigmas, others assume Pois stats\n",
    "           ########################## Uncertainty Settings ##########################\n",
    "           'doDetRes': True, #Include detector resolution effects\n",
    "           'fpeak':1, #0.753 -- 1.0\n",
    "           'doEffsyst':False, #Include systematics from cut efficiencies\n",
    "           'doBurstLeaksyst':False, #Include burst cut leakage systematic\n",
    "           ########################## MCMC Settings ##########################\n",
    "           'nwalkers':128,\n",
    "           'nstep':500000,\n",
    "           'guesses':'Uniform', #Can either be uniform or shape (nwalkers, ndim),\n",
    "           'moves':'DE8020',#'Default': StretchMove, 'DE8020': 80/20 DEMove/DESnookerMove\n",
    "           'saveMCMC':True\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f13373ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "#Parse Options\n",
    "################################################################################\n",
    "mcmc_data['labels']=mcmc_data['Y_labels']+mcmc_data['ER_par_labels']+mcmc_data['NR_par_labels']+mcmc_data['NG_par_labels']\n",
    "mcmc_data['bounds']=mcmc_data['Y_bounds']+mcmc_data['ER_par_bounds']+mcmc_data['NR_par_bounds']+mcmc_data['NG_par_bounds']\n",
    "\n",
    "#Special case if ER and NR are both sim and we want to use the same G4 scaling factor for both:\n",
    "#if (mcmc_data['ER_spec_model']=='sim') and (mcmc_data['NR_spec_model']=='sim'):\n",
    "if (mcmc_data['ER_par_labels']==[r'$scale_{G4}$']) and (mcmc_data['NR_par_labels']==[r'$scale_{G4}$']):\n",
    "    mcmc_data['labels']=mcmc_data['Y_labels']+mcmc_data['NR_par_labels']+mcmc_data['NG_par_labels']\n",
    "    mcmc_data['bounds']=mcmc_data['Y_bounds']+mcmc_data['NR_par_bounds']+mcmc_data['NG_par_bounds']\n",
    "    \n",
    "mcmc_data['ndim']=len(mcmc_data['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bdd624c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Measured Data...\n",
      "PuBe events:  (476731,)\n",
      "Bkg events:  (174636,)\n",
      "N_meas: 195\n",
      "Loading Geant4 Data...\n",
      "(528848, 7)\n",
      "(129555, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../../../python/R68_spec_tools.py:55: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  (eff.dcutEffFit_bkg(Ebins_ctr)/eff.cutEffFit_bkg(Ebins_ctr))**2 +\\\n",
      "../../../python/R68_spec_tools.py:60: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  R_meas_Bkg = N_meas_Bkg/TE_Bkg\n",
      "../../../python/R68_spec_tools.py:62: RuntimeWarning: invalid value encountered in true_divide\n",
      "  dR_meas_PuBe_hi = R_meas_PuBe*np.sqrt( (dN_meas_PuBe_Pois/N_meas_PuBe)**2 +\\\n",
      "../../../python/R68_spec_tools.py:65: RuntimeWarning: invalid value encountered in true_divide\n",
      "  doBurstLeaksyst*(eff.dtrigburstLeak(Ebins_ctr)/N_meas_PuBe)**2 +\\\n",
      "../../../python/R68_spec_tools.py:65: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  doBurstLeaksyst*(eff.dtrigburstLeak(Ebins_ctr)/N_meas_PuBe)**2 +\\\n",
      "../../../python/R68_spec_tools.py:65: RuntimeWarning: invalid value encountered in multiply\n",
      "  doBurstLeaksyst*(eff.dtrigburstLeak(Ebins_ctr)/N_meas_PuBe)**2 +\\\n",
      "../../../python/R68_spec_tools.py:68: RuntimeWarning: invalid value encountered in true_divide\n",
      "  dR_meas_Bkg = R_meas_Bkg*np.sqrt( (dN_meas_Bkg_Pois/N_meas_Bkg)**2 +\\\n",
      "../../../python/R68_spec_tools.py:69: RuntimeWarning: invalid value encountered in multiply\n",
      "  doEffsyst*(dTE_Bkg/TE_Bkg)**2 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading NRs...\n",
      "0.0  min\n",
      "Loading ERs...\n",
      "0.0  min\n",
      "\n",
      "load_frac: 1 \n",
      "\n",
      "Loading (n,gamma) Data...\n",
      "382155\n",
      "dict_keys(['xx', 'yy', 'ex', 'ey'])\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "#Load Data\n",
    "################################################################################\n",
    "import R68_load as r68\n",
    "import R68_spec_tools as spec\n",
    "#Import likelihood functions\n",
    "from likelihoods import *\n",
    "import R68_efficiencies as eff\n",
    "\n",
    "#Set eVee energy binning\n",
    "Emax=mcmc_data['Emax']\n",
    "Ebins=mcmc_data['Ebins']\n",
    "Ebins_ctr=(Ebins[:-1]+Ebins[1:])/2\n",
    "\n",
    "#Set fit range\n",
    "E_lim_min=mcmc_data['Efit_min'] #eVee\n",
    "E_lim_max=mcmc_data['Efit_max'] #eVee\n",
    "spec_bounds=(np.digitize(E_lim_min,Ebins)-1,np.digitize(E_lim_max,Ebins)-1)\n",
    "mcmc_data['spec_bounds']=spec_bounds\n",
    "\n",
    "#Measured spectra background subtraction\n",
    "meas=r68.load_measured(verbose=True)\n",
    "tlive_PuBe=meas['PuBe']['tlive']\n",
    "\n",
    "#Note that N_meas may be either in counts or reconstructed rate, depending on mcmc_data['spectrum_units']\n",
    "#uncertainty is (high,low)\n",
    "#print(\"INPUTS\")\n",
    "#print(\"------------\")\n",
    "#print(\"meas:\",meas)\n",
    "#print(\"Ebins:\",Ebins)\n",
    "#print(\"mcmc_data['Efit_min']:\",mcmc_data['Efit_min'])\n",
    "#print(\"mcmc_data['Efit_max']:\",mcmc_data['Efit_max'])\n",
    "#print(\"mcmc_data['doEffsyst']:\",mcmc_data['doEffsyst'])\n",
    "#print(\"mcmc_data['doBurstLeaksyst']:\",mcmc_data['doBurstLeaksyst'])\n",
    "#print(\"mcmc_data['spectrum_units']:\",mcmc_data['spectrum_units'],'\\n')\n",
    "N_meas,dN_meas=spec.doBkgSub(meas, Ebins, mcmc_data['Efit_min'], mcmc_data['Efit_max'],\\\n",
    "                             doEffsyst=mcmc_data['doEffsyst'], doBurstLeaksyst=mcmc_data['doBurstLeaksyst'],\\\n",
    "                             output=mcmc_data['spectrum_units'])\n",
    "#print(\"OUTPUT\")\n",
    "#print(\"------------\")\n",
    "#print(\"dN_meas[0]:\",dN_meas[0][4:10])\n",
    "#print(\"dN_meas[1]:\",dN_meas[1][4:10])\n",
    "\n",
    "if mcmc_data['likelihood']=='SNorm':\n",
    "    #Precalculate split normal likelihood params if we're going to need it\n",
    "    SNpars=getSNparsArray(N_meas[slice(*spec_bounds)],dN_meas[0][slice(*spec_bounds)],dN_meas[1][slice(*spec_bounds)])\n",
    "    print(\"N_meas:\",len(N_meas[slice(*spec_bounds)]))\n",
    "    #print(\"N_pred:\") #Doesn't exist yet.\n",
    "    SNpars=SNpars.T\n",
    "    #print(len(N_meas[slice(*spec_bounds)]))\n",
    "    #print(len(SNpars[0]))\n",
    "\n",
    "#Load g4 Simulations\n",
    "#No need for this if we're using analytical models for both\n",
    "if (mcmc_data['ER_spec_model']=='sim') or (mcmc_data['NR_spec_model']=='sim'):\n",
    "    g4=r68.load_G4(load_frac=mcmc_data['g4_load_frac'])\n",
    "\n",
    "    #Trim events that won't figure into the analysis range\n",
    "    #Trimmed sim data\n",
    "    if (mcmc_data['ER_spec_model']=='sim'):\n",
    "        Eee_er=np.sum(g4['ER']['E'],axis=1)\n",
    "        Evec_er_cut=(Eee_er>10) & (Eee_er<3e3)\n",
    "        Evec_er=g4['ER']['E'][Evec_er_cut]\n",
    "\n",
    "    if (mcmc_data['NR_spec_model']=='sim'):\n",
    "        Eee_nr=np.sum(g4['NR']['E'],axis=1)\n",
    "        Evec_nr_cut=(Eee_nr>10) & (Eee_nr<30e3)\n",
    "        Evec_nr=g4['NR']['E'][Evec_nr_cut]\n",
    "        #print(\"\\nEvec_nr_cut:\",Evec_nr_cut,'\\n')\n",
    "        #print(\"\\nEee_nr:\",Eee_nr,'\\n')\n",
    "        #print(\"\\ng4['NR']['E']:\",g4['NR']['E'],'\\n')\n",
    "        print(\"\\nload_frac:\",mcmc_data['g4_load_frac'],'\\n')\n",
    "\n",
    "\n",
    "#Load Capture Simulations\n",
    "#print('cap_sim_file:',mcmc_data['cap_sim_file'])\n",
    "#print('cap_rcapture:',mcmc_data['cap_rcapture'])\n",
    "#print('load_frac:',mcmc_data['cap_load_frac'])\n",
    "cap=r68.load_simcap(file=mcmc_data['cap_sim_file'], rcapture=mcmc_data['cap_rcapture'], load_frac=mcmc_data['cap_load_frac'])\n",
    "\n",
    "#Pre-calculate Simulated ER spectrum\n",
    "#This is independent of other params, so we can do this once and reuse it\n",
    "if mcmc_data['ER_spec_model']=='sim':\n",
    "    if mcmc_data['spectrum_units']=='counts':\n",
    "        N_er = spec.buildAvgSimSpectrum_ee(Ebins=Ebins, Evec=Evec_er, Yield=1.0, F=F, scale=1,\\\n",
    "                                           doDetRes=mcmc_data['doDetRes'], fpeak=mcmc_data['fpeak'],\\\n",
    "                                           doEffs=True)    \n",
    "    elif mcmc_data['spectrum_units']=='reco-rate':\n",
    "        N_er = spec.buildAvgSimSpectrum_ee(Ebins=Ebins, Evec=Evec_er, Yield=1.0, F=F, scale=1,\\\n",
    "                                           doDetRes=mcmc_data['doDetRes'], fpeak=mcmc_data['fpeak'],\\\n",
    "                                           doEffs=False)\n",
    "elif mcmc_data['ER_spec_model']=='flat':\n",
    "    N_er = np.ones_like(Ebins_ctr)\n",
    "else:\n",
    "    print('ER_spec_model: ',mcmc_data['ER_spec_model'],' not implemented yet.')\n",
    "        \n",
    "#Import yield models\n",
    "import R68_yield as Yield\n",
    "#Initialize Yield model\n",
    "Y=Yield.Yield('Lind',[0.15])\n",
    "model=mcmc_data['Y_model']\n",
    "Y=Yield.Yield(model,np.zeros(Y.model_npar[model]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71afd439",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "#Calculate Log probability, log(likelihood*prior)\n",
    "################################################################################\n",
    "#theta: array of fit parameters (yield_par0, yield_par1, ...,  F_NR, scale_g4, scale_ng, ...)\n",
    "#    These are in the same order as mcmc_data['labels']\n",
    "#theta_bounds: paramter bounds, shape should be len(theta)x2\n",
    "#spec_bounds: range of bin numbers in spectrum to consider. The analysis range is [bin_low,bin_high)\n",
    "#likelihood: Likelihood function, either 'Pois' or 'Norm'\n",
    "\n",
    "N_pred = None #Setting this up so I can make it global to call it in a moment.\n",
    "\n",
    "def calc_log_likelihood(theta=[0.2,1,1,1,1,1], theta_bounds=tuple(mcmc_data['bounds']), spec_bounds=mcmc_data['spec_bounds'],\n",
    "                  likelihood=mcmc_data['likelihood'],verbose=False,f_ngzero=False): \n",
    "    \n",
    "    #Access the global data\n",
    "    #These must be already defined!!!\n",
    "    global mcmc_data, eff, N_meas, N_er, tlive_PuBe, Evec_nr, cap, Y, N_pred\n",
    "    \n",
    "    if f_ngzero:\n",
    "        theta[-1] = 0\n",
    "    \n",
    "    ############\n",
    "    #Parse fit params\n",
    "    nYpar=Y.npars\n",
    "\n",
    "    Y.set_pars(theta[:nYpar])\n",
    "    F_NR=theta[nYpar] #theta[2] \n",
    "    if verbose:\n",
    "        print(Y.pars,F_NR)\n",
    "    #so the first 3 should definitely be used - why are they acting like they have no effect?\n",
    "    # I must be misunderstanding what this does; these are the only ones that *don't* work.\n",
    "    \n",
    "    #Special check for pchip yield\n",
    "    #Will fail to solve if the parameters are not ordered.\n",
    "    #This effectively includes some parameter ordering in their priors\n",
    "    if not Y.solve():\n",
    "        return -np.inf\n",
    "        \n",
    "    #Grab correct ER scaling factor from theta\n",
    "    if mcmc_data['ER_spec_model']=='sim':\n",
    "        if '$scale_{G4}$' in mcmc_data['labels']:\n",
    "            scale_er=theta[mcmc_data['labels'].index('$scale_{G4}$')]/g4['ER']['tlive']\n",
    "        else:\n",
    "            scale_er=theta[mcmc_data['labels'].index('$scale_{ER}$')]/g4['ER']['tlive']\n",
    "    elif mcmc_data['ER_spec_model']=='flat':\n",
    "        scale_er=theta[mcmc_data['labels'].index(r'$R0_{ER}$')]\n",
    "        \n",
    "    ##########\n",
    "    #Build the spectra\n",
    "    if mcmc_data['spectrum_units']=='counts':\n",
    "        #This includes detector resolution, triggering, and cut efficiency effects\n",
    "        #Does NOT include livetime or write efficiency\n",
    "\n",
    "        #NR\n",
    "        if mcmc_data['NR_spec_model']=='sim':\n",
    "            N_nr=spec.buildAvgSimSpectrum_ee(Ebins=Ebins, Evec=Evec_nr, Yield=Y, F=F_NR, scale=1,\\\n",
    "                                             doDetRes=mcmc_data['doDetRes'], fpeak=mcmc_data['fpeak'],\\\n",
    "                                             doEffs=True)\n",
    "            if '$scale_{G4}$' in mcmc_data['labels']:\n",
    "                scale_nr=theta[mcmc_data['labels'].index('$scale_{G4}$')]/g4['NR']['tlive']\n",
    "            else:\n",
    "                scale_nr=theta[mcmc_data['labels'].index('$scale_{NR}$')]/g4['NR']['tlive']\n",
    "        elif mcmc_data['NR_spec_model']=='exp':\n",
    "            N_nr=np.exp(-Ebins_ctr/theta[mcmc_data['labels'].index(r'$E0_{NR}$')])\n",
    "            scale_nr=theta[mcmc_data['labels'].index(r'$R0_{NR}$')]\n",
    "            \n",
    "        #(n,gamma)\n",
    "        if verbose:\n",
    "            print('spec_units == counts')\n",
    "        N_ng=spec.buildAvgSimSpectrum_ee_composite(Ebins=Ebins, Evec=cap['E'], dEvec=cap['dE'],\\\n",
    "                                                   Yield=Y, F=F_NR, scale=1, doDetRes=mcmc_data['doDetRes'],\\\n",
    "                                                   fpeak=mcmc_data['fpeak'], doEffs=True,verbose=verbose)\n",
    "        scale_ng=theta[mcmc_data['labels'].index('$scale_{ng}$')]/cap['tlive']\n",
    "\n",
    "        #Adjust for livetime and write efficiency\n",
    "        N_pred = (N_nr*scale_nr +\n",
    "                  N_er*scale_er + \n",
    "                  N_ng*scale_ng)*tlive_PuBe*eff.eff_write\n",
    "        #print(N_pred[0])\n",
    "    \n",
    "    elif mcmc_data['spectrum_units']=='reco-rate':\n",
    "        #Don't apply any efficiency effects to simulated spectrum\n",
    "        #NR\n",
    "        if mcmc_data['NR_spec_model']=='sim':\n",
    "            N_nr=spec.buildAvgSimSpectrum_ee(Ebins=Ebins, Evec=Evec_nr, Yield=Y, F=F_NR, scale=1,\\\n",
    "                                             doDetRes=mcmc_data['doDetRes'], fpeak=mcmc_data['fpeak'],\\\n",
    "                                             doEffs=False)\n",
    "            #if verbose:\n",
    "                #Got N_nr lined up! Removing these printouts.\n",
    "                #print(\"N_nr INPUTS\")\n",
    "                #print(\"-------------\")\n",
    "                #print(\"Ebins:\",Ebins)\n",
    "                #print(\"Evec_nr:\",Evec_nr)\n",
    "                #print(\"Yield:\",Y.pars)\n",
    "                #print(\"F_NR:\",F_NR)\n",
    "                #print(\"doDetRes:\",mcmc_data['doDetRes'])\n",
    "                #print(\"fpeak:\",mcmc_data['fpeak'],'\\n')\n",
    "            #print(Y) #It's getting here, but printing Y doesn't tell me anything about it.\n",
    "            if '$scale_{G4}$' in mcmc_data['labels']:\n",
    "                scale_nr=theta[mcmc_data['labels'].index('$scale_{G4}$')]/g4['NR']['tlive']\n",
    "            else:\n",
    "                scale_nr=theta[mcmc_data['labels'].index('$scale_{NR}$')]/g4['NR']['tlive']\n",
    "        elif mcmc_data['NR_spec_model']=='exp':\n",
    "            N_nr=np.exp(-Ebins_ctr/theta[mcmc_data['labels'].index(r'$E0_{NR}$')])\n",
    "            scale_nr=theta[mcmc_data['labels'].index(r'$R0_{NR}$')]\n",
    "        \n",
    "        if verbose:\n",
    "            print('spec_units == reco-rate\\n')\n",
    "            print('N_ng INPUTS')\n",
    "            print('-----------')\n",
    "            print('Ebins:',Ebins)\n",
    "            print('Evec:',cap['E'])\n",
    "            print('dEvec:',cap['dE'])\n",
    "            print('Yield:',Y.pars)\n",
    "            print('F:',F_NR)\n",
    "            print('doDetRes:',mcmc_data['doDetRes'])\n",
    "            print('fpeak:',mcmc_data['fpeak'],'\\n')\n",
    "        #(n,gamma)\n",
    "        N_ng=spec.buildAvgSimSpectrum_ee_composite(Ebins=Ebins, Evec=cap['E'], dEvec=cap['dE'],\\\n",
    "                                                   Yield=Y, F=F_NR, scale=1, doDetRes=mcmc_data['doDetRes'],\\\n",
    "                                                   fpeak=mcmc_data['fpeak'], doEffs=False,verbose=verbose)\n",
    "        scale_ng=theta[mcmc_data['labels'].index('$scale_{ng}$')]/cap['tlive']\n",
    "        \n",
    "        #Calculate rate (though we'll still call them N_* just to be confusing)\n",
    "        # This is where N_pred is first defined. By here, N_meas[()] has shrunk to 96.\n",
    "        # So, I need to redo the SNpars, as N_pred is never changed.\n",
    "        N_pred = (N_nr*scale_nr + \n",
    "                  N_er*scale_er + \n",
    "                  N_ng*scale_ng)\n",
    "        if verbose:\n",
    "            print(\"N_ng:\",N_ng[0:3]) \n",
    "            print(\"N_nr:\", N_nr[0:3])\n",
    "            print(\"F_NR:\", F_NR)\n",
    "            #print(N_pred[0])\n",
    "\n",
    "    ##########\n",
    "    #Calculate the log probability = log prior + log likelihood\n",
    "    ll=None\n",
    "    \n",
    "    if likelihood=='Norm':\n",
    "        ll = ll_norm(N_meas[slice(*spec_bounds)],N_pred[slice(*spec_bounds)])\n",
    "    elif likelihood=='Pois':\n",
    "        ll = ll_pois(N_meas[slice(*spec_bounds)],N_pred[slice(*spec_bounds)])\n",
    "    elif likelihood=='SNorm':\n",
    "        #Precalculate split normal likelihood params if we're going to need it\n",
    "        SNpars=getSNparsArray(N_meas[slice(*spec_bounds)],dN_meas[0][slice(*spec_bounds)],dN_meas[1][slice(*spec_bounds)])\n",
    "        #print(\"N_pred:\") #Doesn't exist yet.\n",
    "        SNpars=SNpars.T\n",
    "        # Here, N_pred[()] and N_meas[slice()] are both 96. However, SNpars already len 195.\n",
    "        ll = ll_SNorm(N_pred[slice(*spec_bounds)],*SNpars) #4 parameters\n",
    "        #print(spec_bounds) #Slice from (5,101) - function parameter.\n",
    "        #print(SNpars[0][0]) #Static, as expected.\n",
    "    else:\n",
    "        print('Error: Bad likelihood')\n",
    "        return None\n",
    "    \n",
    "    if not np.isfinite(ll):\n",
    "        return -np.inf\n",
    "    \n",
    "    return ll #When optimizing, I only want to optimize the log likelihood, not of prior*likelihood.\n",
    "    #So I've slightly altered this function.\n",
    "    \n",
    "    #ll depends on N_pred, which depends on N_nr, which depends depends on F_NR, which is theta[2].\n",
    "    #I have confirmed that the function called when defining N_nr is actually using the variable `F`\n",
    "    #Which F_NR is assigned to. So F_NR **should** affect the output.\n",
    "    #So the returned value should depend on the first three entries of theta, but DEFINITELY on the third.\n",
    "    #why won't it adjust them then?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04e89d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     fun: -504.6329207711302\n",
      "     jac: array([-2.25829750e+02,  7.39018758e+06,  7.92045593e-02,  1.67130001e+02,\n",
      "       -6.71814270e+01,  0.00000000e+00])\n",
      " message: 'Optimization terminated successfully'\n",
      "    nfev: 144\n",
      "     nit: 11\n",
      "    njev: 11\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([3.92023040e-01, 2.90111961e-10, 4.03067305e+02, 3.31232171e+00,\n",
      "       7.39445143e+00, 0.00000000e+00])\n"
     ]
    }
   ],
   "source": [
    "#This is more or less straight from https://emcee.readthedocs.io/en/stable/tutorials/line/\n",
    "#IMPORTANT: CHECK ALL THREE LINES TO ADJUST FOR f_ngzero=True/False\n",
    "#note that bounds cannot be equal; set upper bound of f_ng=1e-9 to keep at zero.\n",
    "\n",
    "nll = lambda *args: -calc_log_likelihood(*args,f_ngzero=True)\n",
    "initial = np.array([4.05799815e-01, 3.00071404e-10, 4.14018676e+02, 3.39896851e+00,7.43590283e+00, 0]) #Based on R68_MCMC_plots_v2.ipynb #set initial last value to 0 if using f_ngzero=True\n",
    "soln = minimize(nll,initial,method = 'SLSQP',bounds=((0,1),(0,1e-9),(0,None),(0,None),(0,None),(0,1e-9)))\n",
    "print(soln)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf619cf7",
   "metadata": {},
   "source": [
    "Raw cells are troubleshooting cells. If you have issues you can uncomment them."
   ]
  },
  {
   "cell_type": "raw",
   "id": "58157771",
   "metadata": {
    "tags": []
   },
   "source": [
    "#Demonstrate irrelevance of first 3 variables\n",
    "print(calc_log_likelihood([0,1,1,1,1,1]))\n",
    "print(calc_log_likelihood([1,1,1,1,1,1]))\n",
    "print(calc_log_likelihood([0,0,1,1,1,1]))\n",
    "print(calc_log_likelihood([0,1,0,1,1,1]))\n",
    "print(calc_log_likelihood([1,1,1,1,1,0]))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e826f2e7",
   "metadata": {
    "tags": []
   },
   "source": [
    "#Looking just at F_NR\n",
    "\n",
    "print(calc_log_likelihood([1,1,0,1,1,1]))\n",
    "print(calc_log_likelihood([1,1,1,1,1,1]))\n",
    "print(calc_log_likelihood([1,1,2,1,1,1]))\n",
    "print(calc_log_likelihood([1,1,3,1,1,1]))\n",
    "print(calc_log_likelihood([1,1,4,1,1,1]))\n",
    "print(calc_log_likelihood([1,1,5,1,1,1]))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "75b632ed",
   "metadata": {
    "tags": []
   },
   "source": [
    "#Looking at Y.pars\n",
    "\n",
    "print(calc_log_likelihood([0.2,0,1,1,1,1]))\n",
    "print(calc_log_likelihood([0.25,0,1,1,1,1]))\n",
    "print(calc_log_likelihood([0.2,0,1,1,1,1]))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cf916401",
   "metadata": {
    "tags": []
   },
   "source": [
    "print(Y.model)\n",
    "Y.set_pars([0,1])\n",
    "print(Y.calc(10000))\n",
    "Y.set_pars([1,0])\n",
    "print(Y.calc(10000))\n",
    "\n",
    "# ALTERING THE YIELD PARAMETERS DOES ALTER THE YIELDED AMOUNT AS EXPECTED SO WHY DOES IT NOT WORK AGH\n",
    "# And the function *does* call Yield.calc() in a variable that influences the final output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63fe0b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "k,q,F_NR,f_ER,f_NR,f_ng = soln.x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a10187",
   "metadata": {},
   "source": [
    "# Get Chisquare!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11b689b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL: Sor \n",
      "\n",
      "STATISTICS\n",
      "------------\n",
      "Log likelihood: 504.6329207711302\n",
      "Chisq: 1797.770039381899\n",
      "Chisq/DoF: 9.512010790380419 \n",
      "\n",
      "PARAMETERS\n",
      "------------\n",
      "k = 0.392\n",
      "q = 2.90112e-10\n",
      "F_NR = 403.067\n",
      "f_ER = 3.312\n",
      "f_NR = 7.394\n",
      "f_ng = 0.000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"MODEL:\",Y.model,\"\\n\")\n",
    "\n",
    "print(\"STATISTICS\")\n",
    "print(\"------------\")\n",
    "\n",
    "print(\"Log likelihood:\",calc_log_likelihood(soln.x))\n",
    "\n",
    "if mcmc_data['likelihood'] == 'SNorm':\n",
    "    chi = chisq(N_meas[slice(*spec_bounds)],N_pred[slice(*spec_bounds)],0.5*(dN_meas[0]+dN_meas[1])[slice(*spec_bounds)])\n",
    "else:\n",
    "    print(\"Sorry, I didn't make that yet. See cell 21 of R68_MCMC_process.ipynb for chisq calc.\")\n",
    "    print(\"Also now you get an error, probably.\")\n",
    "    print(\"▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓\\n▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░░░░▓▓▓▓▓\\n▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░░░░▓▓▓▓▓\\n▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░░░░▓▓▓▓▓░░░▓▓\\n▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░░▓▓▓░▓▓▓▓▓▓░░░▓▓\\n▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░░▓▓▓▓▓▓▓▓░▓░░░▓▓\\n▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░░░░░▓▓▓▓▓▓▓░▓░░░▓▓▓▓▓\\n▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░░░░░▓░▓░▓▓▓▓▓▓▓▓▓▓▓░░░▓▓▓▓\\n▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░░░░▓▓▓▓▓▓▓▓▓▓▓░▓░▓░░░▓▓▓▓▓\\n▓▓▓▓▓▓░░░░░░░░░░░░░░░░▓▓▓▓▓▓▓▓▓▓▓░▓░▓░▓▓░░░▓▓▓▓▓▓▓\\n▓▓▓░░░░▓░▓░▓░▓░▓░▓░▓░▓▓▓▓▓▓▓░▓▓▓░▓░▓░▓░▓░░░▓▓▓▓▓▓▓\\n▓▓▓░░░▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░▓░▓░▓░▓░▓░▓▓░░░▓▓▓▓▓▓▓\\n▓▓▓▓▓▓░░░▓▓▓▓▓▓▓░▓░▓▓▓▓▓▓▓▓▓▓▓░▓░▓░▓░▓▓▓░░░▓▓▓▓▓▓▓\\n▓▓▓▓▓▓▓░░░░░░░░░░▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░▓░░░▓▓▓▓▓▓▓▓▓▓\\n▓▓▓▓▓▓▓▓░░░░░░░░░▓░▓░▓░▓░▓░▓▓▓▓▓▓▓▓▓▓░░░▓▓▓▓▓▓▓▓▓▓\\n▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░░░░░░▓▓▓▓▓▓▓▓▓░▓░▓░▓▓░░░▓▓▓▓▓▓▓\\n▓▓▓▓▓▓▓▓▓▓▓▓▓▓░▓░░░░░░░░░░░░░░░░░▓░▓▓▓▓▓░░░▓░▓▓▓▓▓\\n▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░▓▓▓░░░░░░░░░░░░░▓▓▓▓▓▓▓░▓▓▓░░░▓▓▓▓\\n▓▓▓▓▓▓▓▓▓▓▓░░░░░░▓▓░░░░░▓▓▓░░░░░░░░░░░▓▓▓▓▓▓▓░░░▓▓\\n▓▓▓▓▓▓▓▓▓░▓░░░░░░▓▓░░░░░▓▓▓░░░░░░░░░░░▓▓░░░▓▓░░░▓░\\n▓▓▓▓▓▓▓▓░░░▓▓▓░░░░░░░░░░▓▓▓░░░░░░░░░░▓▓▓░░░▓▓▓▓▓░░\\n▓▓▓▓▓▓░░░▓▓░░░░░░░░░░░░░░░░░░░░░░░░░░░░░▓▓▓░░░░░▓▓\\n▓▓▓▓▓▓░░░▓▓░░░░░░░░░░░░░░░░░░░░░░░░░░░░░▓▓▓░░░░░▓▓\\n▓▓▓▓▓▓░░░▓▓▓▓▓▓▓░░░░░░░░▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░▓▓▓▓▓\\n▓▓▓▓▓▓░░░░░▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░░░░░░░▓▓▓▓▓░░░▓▓▓▓▓▓▓\\n▓▓▓▓▓▓░░░░░░▓░▓▓▓▓▓▓▓▓▓▓▓░▓░░░░░░░░▓▓▓▓▓░░░▓▓▓▓▓▓▓\\n▓▓▓░░░▓▓▓▓▓░░░▓▓▓▓▓▓▓▓░░░░░▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░▓▓▓▓▓\\n▓▓▓░░░▓▓▓▓▓░░░▓▓▓▓▓░░░░░░░░▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░▓▓▓▓▓\\n▓▓▓░░░▓▓▓▓▓░░░▓▓▓▓▓░░░░░░░░▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░░▓▓▓▓▓\\n▓▓▓▓▓▓░░░░░▓▓▓▓▓▓▓▓▓▓▓▓▓░░░▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░▓▓▓▓▓\\n▓▓▓▓▓▓░░░▓░░░░▓▓▓▓▓▓▓▓▓▓░░░▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░▓▓▓▓▓\\n▓▓▓▓▓▓░░░▓▓░░░▓▓▓▓▓▓▓▓▓▓░░░▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░▓▓▓▓▓\\n▓▓▓▓▓▓░░░▓▓░░░▓▓▓▓▓░░░░░░░░▓▓▓▓▓▓▓▓▓▓▓▓▓░░░▓▓▓▓▓▓▓\\n▓▓▓▓▓▓░░░▓▓░▓░░░▓▓▓░░░░░░░▓░░░▓▓▓▓▓▓▓▓▓▓░░░▓▓▓▓▓▓▓\\n▓▓▓▓▓▓░░░▓▓▓▓▓░░░▓▓▓▓▓▓▓▓▓▓░░░▓▓▓▓▓▓▓▓▓▓░░░▓▓▓▓▓▓▓\\n▓▓▓▓▓▓░░░▓▓▓▓▓▓▓░░░▓▓▓▓▓▓▓▓░░░▓▓▓▓▓▓▓▓▓▓░░░▓▓▓▓▓▓▓\\n▓▓▓▓▓▓░░░▓▓▓▓▓▓▓░░░░░░░░░▓▓░░░░░▓▓▓▓▓▓░░░░░░░▓▓▓▓▓\\n▓▓▓▓▓▓░░░▓▓▓▓▓▓▓▓▓▓░░░░░░▓▓▓▓░░░▓▓▓▓▓░░░▓▓▓░░░▓▓▓▓\\n▓▓▓░░░▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░░░░░▓▓▓▓▓▓▓░░░▓▓\\n▓▓▓░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░▓▓\\n▓▓▓▓▓▓░░░░░░░░░░░░░░░░░░░░░░░░░░▓▓▓▓▓▓░░░░░░░▓▓▓▓▓\\n▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓ \")\n",
    "    print(\"(Source: https://steamcommunity.com/groups/ascii-art/discussions/0/312265672109050684/ )\")\n",
    "    print(\"\")\n",
    "dof=np.diff(mcmc_data['spec_bounds'])[0]-mcmc_data['ndim']\n",
    "\n",
    "print('Chisq:',chi)\n",
    "print('Chisq/DoF:',chi/dof,\"\\n\")\n",
    "\n",
    "print(\"PARAMETERS\")\n",
    "print(\"------------\")\n",
    "\n",
    "print(\"k = {0:.3f}\".format(k))\n",
    "print(\"q = {0:.5e}\".format(q))\n",
    "print(\"F_NR = {0:.3f}\".format(F_NR))\n",
    "print(\"f_ER = {0:.3f}\".format(f_ER))\n",
    "print(\"f_NR = {0:.3f}\".format(f_NR))\n",
    "print(\"f_ng = {0:.3f}\\n\".format(f_ng))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47de74dd-207a-43bb-80bb-70cc621d3822",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL: Sor \n",
      "\n",
      "STATISTICS\n",
      "------------\n",
      "[0.4166, 2.9838e-10] 413\n",
      "spec_units == reco-rate\n",
      "\n",
      "N_ng INPUTS\n",
      "-----------\n",
      "Ebins: [   0.   10.   20.   30.   40.   50.   60.   70.   80.   90.  100.  110.\n",
      "  120.  130.  140.  150.  160.  170.  180.  190.  200.  210.  220.  230.\n",
      "  240.  250.  260.  270.  280.  290.  300.  310.  320.  330.  340.  350.\n",
      "  360.  370.  380.  390.  400.  410.  420.  430.  440.  450.  460.  470.\n",
      "  480.  490.  500.  510.  520.  530.  540.  550.  560.  570.  580.  590.\n",
      "  600.  610.  620.  630.  640.  650.  660.  670.  680.  690.  700.  710.\n",
      "  720.  730.  740.  750.  760.  770.  780.  790.  800.  810.  820.  830.\n",
      "  840.  850.  860.  870.  880.  890.  900.  910.  920.  930.  940.  950.\n",
      "  960.  970.  980.  990. 1000. 1010. 1020. 1030. 1040. 1050. 1060. 1070.\n",
      " 1080. 1090. 1100. 1110. 1120. 1130. 1140. 1150. 1160. 1170. 1180. 1190.\n",
      " 1200. 1210. 1220. 1230. 1240. 1250. 1260. 1270. 1280. 1290. 1300. 1310.\n",
      " 1320. 1330. 1340. 1350. 1360. 1370. 1380. 1390. 1400. 1410. 1420. 1430.\n",
      " 1440. 1450. 1460. 1470. 1480. 1490. 1500. 1510. 1520. 1530. 1540. 1550.\n",
      " 1560. 1570. 1580. 1590. 1600. 1610. 1620. 1630. 1640. 1650. 1660. 1670.\n",
      " 1680. 1690. 1700. 1710. 1720. 1730. 1740. 1750. 1760. 1770. 1780. 1790.\n",
      " 1800. 1810. 1820. 1830. 1840. 1850. 1860. 1870. 1880. 1890. 1900. 1910.\n",
      " 1920. 1930. 1940. 1950. 1960. 1970. 1980. 1990. 2000. 2010. 2020. 2030.\n",
      " 2040. 2050. 2060. 2070. 2080. 2090. 2100. 2110. 2120. 2130. 2140. 2150.\n",
      " 2160. 2170. 2180. 2190. 2200. 2210. 2220. 2230. 2240. 2250. 2260. 2270.\n",
      " 2280. 2290. 2300. 2310. 2320. 2330. 2340. 2350. 2360. 2370. 2380. 2390.\n",
      " 2400. 2410. 2420. 2430. 2440. 2450. 2460. 2470. 2480. 2490. 2500.]\n",
      "Evec: [[ 232.05056808  575.71120363    0.        ]\n",
      " [ 232.05056808  326.15069451    0.        ]\n",
      " [ 232.05056808 1157.95769085    0.        ]\n",
      " ...\n",
      " [ 232.05056808 1058.81366424    0.        ]\n",
      " [ 232.05056808  288.46516692    0.        ]\n",
      " [ 232.05056808  181.14052608    0.        ]]\n",
      "dEvec: [[2.62192716e+00 5.75711204e+02 0.00000000e+00]\n",
      " [5.15870227e+00 3.26150695e+02 0.00000000e+00]\n",
      " [6.61769101e+00 1.15795769e+03 0.00000000e+00]\n",
      " ...\n",
      " [9.23949315e-01 1.05881366e+03 0.00000000e+00]\n",
      " [2.90175416e+00 2.88465167e+02 0.00000000e+00]\n",
      " [3.42749459e+00 1.81140526e+02 0.00000000e+00]]\n",
      "Yield: [0.4166, 2.9838e-10]\n",
      "F: 413\n",
      "doDetRes: True\n",
      "fpeak: 1 \n",
      "\n",
      "In-function yield: [0.4166, 2.9838e-10] In-function F_NR: 413\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_28645/1344209298.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Log likelihood:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcalc_log_likelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmcmc_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'likelihood'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'SNorm'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_28645/711822650.py\u001b[0m in \u001b[0;36mcalc_log_likelihood\u001b[0;34m(theta, theta_bounds, spec_bounds, likelihood, verbose, f_ngzero)\u001b[0m\n\u001b[1;32m    120\u001b[0m                                                    \u001b[0mYield\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mF_NR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoDetRes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmcmc_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'doDetRes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                                                    fpeak=mcmc_data['fpeak'], doEffs=False,verbose=verbose)\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0mscale_ng\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmcmc_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'$scale_{ng}$'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mcap\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tlive'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;31m#Calculate rate (though we'll still call them N_* just to be confusing)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Manual statistics calculation\n",
    "\n",
    "params          = [0.4166,2.9838e-10,413,409.8,3.3]  #Provide parameters here\n",
    "#likelihoodmodel = 'SNorm'        #Provide likelihood model here, but this is the only one that works.\n",
    "\n",
    "print(\"MODEL:\",Y.model,\"\\n\")\n",
    "\n",
    "print(\"STATISTICS\")\n",
    "print(\"------------\")\n",
    "\n",
    "print(\"Log likelihood:\",calc_log_likelihood(params,verbose=True))\n",
    "\n",
    "if mcmc_data['likelihood'] == 'SNorm':\n",
    "    chi = chisq(N_meas[slice(*spec_bounds)],N_pred[slice(*spec_bounds)],0.5*(dN_meas[0]+dN_meas[1])[slice(*spec_bounds)])\n",
    "else:\n",
    "    print(\"Sorry, I didn't make that yet. See cell 21 of R68_MCMC_process.ipynb for chisq calc.\")\n",
    "    print(\"Also now you get an error, probably.\")\n",
    "    print(\"▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓\\n▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░░░░▓▓▓▓▓\\n▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░░░░▓▓▓▓▓\\n▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░░░░▓▓▓▓▓░░░▓▓\\n▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░░▓▓▓░▓▓▓▓▓▓░░░▓▓\\n▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░░▓▓▓▓▓▓▓▓░▓░░░▓▓\\n▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░░░░░▓▓▓▓▓▓▓░▓░░░▓▓▓▓▓\\n▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░░░░░▓░▓░▓▓▓▓▓▓▓▓▓▓▓░░░▓▓▓▓\\n▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░░░░▓▓▓▓▓▓▓▓▓▓▓░▓░▓░░░▓▓▓▓▓\\n▓▓▓▓▓▓░░░░░░░░░░░░░░░░▓▓▓▓▓▓▓▓▓▓▓░▓░▓░▓▓░░░▓▓▓▓▓▓▓\\n▓▓▓░░░░▓░▓░▓░▓░▓░▓░▓░▓▓▓▓▓▓▓░▓▓▓░▓░▓░▓░▓░░░▓▓▓▓▓▓▓\\n▓▓▓░░░▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░▓░▓░▓░▓░▓░▓▓░░░▓▓▓▓▓▓▓\\n▓▓▓▓▓▓░░░▓▓▓▓▓▓▓░▓░▓▓▓▓▓▓▓▓▓▓▓░▓░▓░▓░▓▓▓░░░▓▓▓▓▓▓▓\\n▓▓▓▓▓▓▓░░░░░░░░░░▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░▓░░░▓▓▓▓▓▓▓▓▓▓\\n▓▓▓▓▓▓▓▓░░░░░░░░░▓░▓░▓░▓░▓░▓▓▓▓▓▓▓▓▓▓░░░▓▓▓▓▓▓▓▓▓▓\\n▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░░░░░░▓▓▓▓▓▓▓▓▓░▓░▓░▓▓░░░▓▓▓▓▓▓▓\\n▓▓▓▓▓▓▓▓▓▓▓▓▓▓░▓░░░░░░░░░░░░░░░░░▓░▓▓▓▓▓░░░▓░▓▓▓▓▓\\n▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░▓▓▓░░░░░░░░░░░░░▓▓▓▓▓▓▓░▓▓▓░░░▓▓▓▓\\n▓▓▓▓▓▓▓▓▓▓▓░░░░░░▓▓░░░░░▓▓▓░░░░░░░░░░░▓▓▓▓▓▓▓░░░▓▓\\n▓▓▓▓▓▓▓▓▓░▓░░░░░░▓▓░░░░░▓▓▓░░░░░░░░░░░▓▓░░░▓▓░░░▓░\\n▓▓▓▓▓▓▓▓░░░▓▓▓░░░░░░░░░░▓▓▓░░░░░░░░░░▓▓▓░░░▓▓▓▓▓░░\\n▓▓▓▓▓▓░░░▓▓░░░░░░░░░░░░░░░░░░░░░░░░░░░░░▓▓▓░░░░░▓▓\\n▓▓▓▓▓▓░░░▓▓░░░░░░░░░░░░░░░░░░░░░░░░░░░░░▓▓▓░░░░░▓▓\\n▓▓▓▓▓▓░░░▓▓▓▓▓▓▓░░░░░░░░▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░▓▓▓▓▓\\n▓▓▓▓▓▓░░░░░▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░░░░░░░▓▓▓▓▓░░░▓▓▓▓▓▓▓\\n▓▓▓▓▓▓░░░░░░▓░▓▓▓▓▓▓▓▓▓▓▓░▓░░░░░░░░▓▓▓▓▓░░░▓▓▓▓▓▓▓\\n▓▓▓░░░▓▓▓▓▓░░░▓▓▓▓▓▓▓▓░░░░░▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░▓▓▓▓▓\\n▓▓▓░░░▓▓▓▓▓░░░▓▓▓▓▓░░░░░░░░▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░▓▓▓▓▓\\n▓▓▓░░░▓▓▓▓▓░░░▓▓▓▓▓░░░░░░░░▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░░▓▓▓▓▓\\n▓▓▓▓▓▓░░░░░▓▓▓▓▓▓▓▓▓▓▓▓▓░░░▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░▓▓▓▓▓\\n▓▓▓▓▓▓░░░▓░░░░▓▓▓▓▓▓▓▓▓▓░░░▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░▓▓▓▓▓\\n▓▓▓▓▓▓░░░▓▓░░░▓▓▓▓▓▓▓▓▓▓░░░▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░▓▓▓▓▓\\n▓▓▓▓▓▓░░░▓▓░░░▓▓▓▓▓░░░░░░░░▓▓▓▓▓▓▓▓▓▓▓▓▓░░░▓▓▓▓▓▓▓\\n▓▓▓▓▓▓░░░▓▓░▓░░░▓▓▓░░░░░░░▓░░░▓▓▓▓▓▓▓▓▓▓░░░▓▓▓▓▓▓▓\\n▓▓▓▓▓▓░░░▓▓▓▓▓░░░▓▓▓▓▓▓▓▓▓▓░░░▓▓▓▓▓▓▓▓▓▓░░░▓▓▓▓▓▓▓\\n▓▓▓▓▓▓░░░▓▓▓▓▓▓▓░░░▓▓▓▓▓▓▓▓░░░▓▓▓▓▓▓▓▓▓▓░░░▓▓▓▓▓▓▓\\n▓▓▓▓▓▓░░░▓▓▓▓▓▓▓░░░░░░░░░▓▓░░░░░▓▓▓▓▓▓░░░░░░░▓▓▓▓▓\\n▓▓▓▓▓▓░░░▓▓▓▓▓▓▓▓▓▓░░░░░░▓▓▓▓░░░▓▓▓▓▓░░░▓▓▓░░░▓▓▓▓\\n▓▓▓░░░▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░░░░░▓▓▓▓▓▓▓░░░▓▓\\n▓▓▓░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░▓▓\\n▓▓▓▓▓▓░░░░░░░░░░░░░░░░░░░░░░░░░░▓▓▓▓▓▓░░░░░░░▓▓▓▓▓\\n▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓ \")\n",
    "    print(\"(Source: https://steamcommunity.com/groups/ascii-art/discussions/0/312265672109050684/ )\")\n",
    "    print(\"\")\n",
    "dof=np.diff(mcmc_data['spec_bounds'])[0]-mcmc_data['ndim']\n",
    "\n",
    "print('Chisq:',chi)\n",
    "print('Chisq/DoF:',chi/dof,\"\\n\")\n",
    "\n",
    "print(\"PARAMETERS\")\n",
    "print(\"------------\")\n",
    "\n",
    "print(\"k = {0:.3f}\".format(params[0]))\n",
    "#print(\"q = {0:.3f}\".format(params[1]))\n",
    "print(\"F_NR = {0:.3f}\".format(params[1]))\n",
    "print(\"f_ER = {0:.3f}\".format(params[2]))\n",
    "print(\"f_NR = {0:.3f}\".format(params[3]))\n",
    "print(\"f_ng = {0:.3f}\\n\".format(params[4]))\n",
    "\n",
    "print(\"VECTORS\")\n",
    "print(\"------------\")\n",
    "\n",
    "print(\"N_meas:\",N_meas[3:10])\n",
    "print(\"N_pred:\",N_pred[:5])\n",
    "print(\"dN_meas[0]:\",dN_meas[0][3:10])\n",
    "print(\"dN_meas[1]:\",dN_meas[1][3:10])\n",
    "\n",
    "print(\"COMMENT:\")\n",
    "print(\"From Nick's version of MCMC calculations.\\n\") #Any comment you want to be printed along with the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52ec602",
   "metadata": {},
   "source": [
    "# Chisquare Optimization\n",
    "\n",
    "Optimize chisquare instead of -log(L)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "799f2102",
   "metadata": {},
   "source": [
    "def chi(params):\n",
    "    calc_log_likelihood(params)\n",
    "    return chisq(N_meas[slice(*spec_bounds)],N_pred[slice(*spec_bounds)],0.5*(dN_meas[0]+dN_meas[1])[slice(*spec_bounds)])\n",
    "initial = np.array([0.119, 4.370, 5.974,3.163, 2.584]) #Based on R68_MCMC_plots_v2.ipynb #set initial last value to 0 if using f_ngzero=True\n",
    "soln = minimize(chi,initial,method = 'SLSQP',bounds=((0,1),(0,None),(0,None),(0,None),(0,None)))\n",
    "print(soln)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "58b00060",
   "metadata": {},
   "source": [
    "k,F_NR,f_ER,f_NR,f_ng = soln.x\n",
    "print(\"MODEL:\",Y.model,\"\\n\")\n",
    "\n",
    "print(\"STATISTICS\")\n",
    "print(\"------------\")\n",
    "\n",
    "print(\"Log likelihood:\",calc_log_likelihood(soln.x))\n",
    "\n",
    "if mcmc_data['likelihood'] == 'SNorm':\n",
    "    chi = chisq(N_meas[slice(*spec_bounds)],N_pred[slice(*spec_bounds)],0.5*(dN_meas[0]+dN_meas[1])[slice(*spec_bounds)])\n",
    "else:\n",
    "    print(\"Sorry, I didn't make that yet. See cell 21 of R68_MCMC_process.ipynb for chisq calc.\")\n",
    "    print(\"Also now you get an error, probably.\")\n",
    "    print(\"▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓\\n▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░░░░▓▓▓▓▓\\n▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░░░░▓▓▓▓▓\\n▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░░░░▓▓▓▓▓░░░▓▓\\n▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░░▓▓▓░▓▓▓▓▓▓░░░▓▓\\n▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░░▓▓▓▓▓▓▓▓░▓░░░▓▓\\n▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░░░░░▓▓▓▓▓▓▓░▓░░░▓▓▓▓▓\\n▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░░░░░▓░▓░▓▓▓▓▓▓▓▓▓▓▓░░░▓▓▓▓\\n▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░░░░▓▓▓▓▓▓▓▓▓▓▓░▓░▓░░░▓▓▓▓▓\\n▓▓▓▓▓▓░░░░░░░░░░░░░░░░▓▓▓▓▓▓▓▓▓▓▓░▓░▓░▓▓░░░▓▓▓▓▓▓▓\\n▓▓▓░░░░▓░▓░▓░▓░▓░▓░▓░▓▓▓▓▓▓▓░▓▓▓░▓░▓░▓░▓░░░▓▓▓▓▓▓▓\\n▓▓▓░░░▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░▓░▓░▓░▓░▓░▓▓░░░▓▓▓▓▓▓▓\\n▓▓▓▓▓▓░░░▓▓▓▓▓▓▓░▓░▓▓▓▓▓▓▓▓▓▓▓░▓░▓░▓░▓▓▓░░░▓▓▓▓▓▓▓\\n▓▓▓▓▓▓▓░░░░░░░░░░▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░▓░░░▓▓▓▓▓▓▓▓▓▓\\n▓▓▓▓▓▓▓▓░░░░░░░░░▓░▓░▓░▓░▓░▓▓▓▓▓▓▓▓▓▓░░░▓▓▓▓▓▓▓▓▓▓\\n▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░░░░░░▓▓▓▓▓▓▓▓▓░▓░▓░▓▓░░░▓▓▓▓▓▓▓\\n▓▓▓▓▓▓▓▓▓▓▓▓▓▓░▓░░░░░░░░░░░░░░░░░▓░▓▓▓▓▓░░░▓░▓▓▓▓▓\\n▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░▓▓▓░░░░░░░░░░░░░▓▓▓▓▓▓▓░▓▓▓░░░▓▓▓▓\\n▓▓▓▓▓▓▓▓▓▓▓░░░░░░▓▓░░░░░▓▓▓░░░░░░░░░░░▓▓▓▓▓▓▓░░░▓▓\\n▓▓▓▓▓▓▓▓▓░▓░░░░░░▓▓░░░░░▓▓▓░░░░░░░░░░░▓▓░░░▓▓░░░▓░\\n▓▓▓▓▓▓▓▓░░░▓▓▓░░░░░░░░░░▓▓▓░░░░░░░░░░▓▓▓░░░▓▓▓▓▓░░\\n▓▓▓▓▓▓░░░▓▓░░░░░░░░░░░░░░░░░░░░░░░░░░░░░▓▓▓░░░░░▓▓\\n▓▓▓▓▓▓░░░▓▓░░░░░░░░░░░░░░░░░░░░░░░░░░░░░▓▓▓░░░░░▓▓\\n▓▓▓▓▓▓░░░▓▓▓▓▓▓▓░░░░░░░░▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░▓▓▓▓▓\\n▓▓▓▓▓▓░░░░░▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░░░░░░░▓▓▓▓▓░░░▓▓▓▓▓▓▓\\n▓▓▓▓▓▓░░░░░░▓░▓▓▓▓▓▓▓▓▓▓▓░▓░░░░░░░░▓▓▓▓▓░░░▓▓▓▓▓▓▓\\n▓▓▓░░░▓▓▓▓▓░░░▓▓▓▓▓▓▓▓░░░░░▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░▓▓▓▓▓\\n▓▓▓░░░▓▓▓▓▓░░░▓▓▓▓▓░░░░░░░░▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░▓▓▓▓▓\\n▓▓▓░░░▓▓▓▓▓░░░▓▓▓▓▓░░░░░░░░▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░░▓▓▓▓▓\\n▓▓▓▓▓▓░░░░░▓▓▓▓▓▓▓▓▓▓▓▓▓░░░▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░▓▓▓▓▓\\n▓▓▓▓▓▓░░░▓░░░░▓▓▓▓▓▓▓▓▓▓░░░▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░▓▓▓▓▓\\n▓▓▓▓▓▓░░░▓▓░░░▓▓▓▓▓▓▓▓▓▓░░░▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░▓▓▓▓▓\\n▓▓▓▓▓▓░░░▓▓░░░▓▓▓▓▓░░░░░░░░▓▓▓▓▓▓▓▓▓▓▓▓▓░░░▓▓▓▓▓▓▓\\n▓▓▓▓▓▓░░░▓▓░▓░░░▓▓▓░░░░░░░▓░░░▓▓▓▓▓▓▓▓▓▓░░░▓▓▓▓▓▓▓\\n▓▓▓▓▓▓░░░▓▓▓▓▓░░░▓▓▓▓▓▓▓▓▓▓░░░▓▓▓▓▓▓▓▓▓▓░░░▓▓▓▓▓▓▓\\n▓▓▓▓▓▓░░░▓▓▓▓▓▓▓░░░▓▓▓▓▓▓▓▓░░░▓▓▓▓▓▓▓▓▓▓░░░▓▓▓▓▓▓▓\\n▓▓▓▓▓▓░░░▓▓▓▓▓▓▓░░░░░░░░░▓▓░░░░░▓▓▓▓▓▓░░░░░░░▓▓▓▓▓\\n▓▓▓▓▓▓░░░▓▓▓▓▓▓▓▓▓▓░░░░░░▓▓▓▓░░░▓▓▓▓▓░░░▓▓▓░░░▓▓▓▓\\n▓▓▓░░░▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░░░░░▓▓▓▓▓▓▓░░░▓▓\\n▓▓▓░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░▓▓\\n▓▓▓▓▓▓░░░░░░░░░░░░░░░░░░░░░░░░░░▓▓▓▓▓▓░░░░░░░▓▓▓▓▓\\n▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓ \")\n",
    "    print(\"(Source: https://steamcommunity.com/groups/ascii-art/discussions/0/312265672109050684/ )\")\n",
    "    print(\"\")\n",
    "dof=np.diff(mcmc_data['spec_bounds'])[0]-mcmc_data['ndim']\n",
    "\n",
    "print('Chisq:',chi)\n",
    "print('Chisq/DoF:',chi/dof,\"\\n\")\n",
    "\n",
    "print(\"PARAMETERS\")\n",
    "print(\"------------\")\n",
    "\n",
    "print(\"k = {0:.3f}\".format(k))\n",
    "#print(\"q = {0:.3f}\".format(q))\n",
    "print(\"F_NR = {0:.3f}\".format(F_NR))\n",
    "print(\"f_ER = {0:.3f}\".format(f_ER))\n",
    "print(\"f_NR = {0:.3f}\".format(f_NR))\n",
    "print(\"f_ng = {0:.3f}\\n\".format(f_ng))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
