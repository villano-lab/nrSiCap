{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# R68 MCMC\n",
    "\n",
    "Use MCMC to estimate yield model parameters for R68 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../mplstyles\n",
      "3.1.1\n",
      "/data/chocula/mast/cdms/analysis/run068/R68_paper2019/mplstyles\n"
     ]
    }
   ],
   "source": [
    "#Set up notebook and load some R68 constants (V, eps, etc.)\n",
    "exec(open(\"nb_setup.py\").read())#Is there a better way to do this?\n",
    "from constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Measured Data...\n",
      "(480634,)\n",
      "(174510,)\n",
      "Loading Geant4 Data...\n",
      "(528848, 7)\n",
      "(129555, 7)\n",
      "Loading NRs...\n",
      "1.2  min\n",
      "Loading ERs...\n",
      "0.3  min\n",
      "Loading (n,gamma) Data...\n",
      "200000\n"
     ]
    }
   ],
   "source": [
    "#Load the data\n",
    "import R68_load as r68\n",
    "\n",
    "meas=r68.load_measured()\n",
    "g4=r68.load_G4()\n",
    "cap=r68.load_simcap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Energy binning\n",
    "Emax = 2000 #eVee\n",
    "Ebins=np.linspace(0,Emax,201)\n",
    "Ebin_ctr=(Ebins[:-1]+Ebins[1:])/2\n",
    "\n",
    "#Measured spectra\n",
    "N_meas_PuBe,_ = np.histogram(meas['PuBe']['E'],bins=Ebins)\n",
    "N_meas_Bkg,_ = np.histogram(meas['Bkg']['E'],bins=Ebins)\n",
    "\n",
    "tlive_PuBe = meas['PuBe']['tlive']\n",
    "tlive_Bkg = meas['Bkg']['tlive']\n",
    "#We'll scale everything to the PuBe live time and work with counts, not rate, to get the Poisson stats right\n",
    "\n",
    "N_meas_Bkg_scaled = N_meas_Bkg * tlive_PuBe/tlive_Bkg\n",
    "\n",
    "#Estimate of counts due to PuBe\n",
    "N_meas = N_meas_PuBe - N_meas_Bkg_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['xx', 'yy', 'ex', 'ey'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mast/python/miniconda3/envs/nr_fano/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/home/mast/python/miniconda3/envs/nr_fano/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "#Import yield models\n",
    "import R68_yield as Yield\n",
    "import R68_spec_tools as spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Lind: Lindhard', 'Chav: Chavarria', 'Sor: Sorenson', 'Damic: Extrapolated Damic model']\n"
     ]
    }
   ],
   "source": [
    "Y=Yield.Yield('Lind',[0.15])\n",
    "print(Y.models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define likelihood functions\n",
    "from scipy.special import factorial, gamma\n",
    "\n",
    "#Poisson likelihood of measuring k given expected mean of lambda\n",
    "def pois_likelihood(k, lamb):\n",
    "    return (lamb**k)*np.exp(-lamb)/gamma(k+1.)\n",
    "\n",
    "#Poisson log-likelihood\n",
    "#k: observed counts\n",
    "#lamb: expected (model) counts\n",
    "def ll_pois(k, lamb):   \n",
    "    if np.sum(lamb<=0):\n",
    "        return -np.inf\n",
    "    \n",
    "    return np.sum(k*np.log(lamb) - lamb - np.log(gamma(k+1.)))\n",
    "\n",
    "#Normal log-likelihood, limit of Poisson for large lambda\n",
    "#k: observed counts\n",
    "#lamb: expected (model) counts\n",
    "def ll_norm(k,lamb):\n",
    "    if np.sum(lamb<=0):\n",
    "        return -np.inf\n",
    "    \n",
    "    return np.sum(-0.5*np.log(2*np.pi*lamb) - (k-lamb)**2/(2*lamb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Log of flat prior functions\n",
    "#theta: array of parameter values\n",
    "#bounds: array of parameter bounds. shape should be len(theta)x2\n",
    "def lp_flat(theta, bounds):\n",
    "    #for itheta,ibounds in zip(theta,bounds):\n",
    "    #    if not (ibounds[0] < itheta < ibounds[1]):\n",
    "    #        return -np.inf\n",
    "        \n",
    "    #return 0.0\n",
    "    \n",
    "    if (np.array(theta_bounds)[:,0]<theta).all() and (theta<np.array(theta_bounds)[:,1]).all():\n",
    "        return 0.0\n",
    "    return -np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate Log probability, log(likelihood*prior)\n",
    "#\n",
    "#model: pre-defined Yield model\n",
    "#theta: array of fit parameters (yield, F_NR, etc.)\n",
    "#theta_bounds: paramter bounds, shape should be len(theta)x2\n",
    "#spec_bounds: range of bin numbers in spectrum to consider. The analysis range is [bin_low,bin_high)\n",
    "#likelihood: Likelihood function, either 'Pois' or 'Norm'\n",
    "\n",
    "def calc_log_prob(model='Lind',theta=[0.2, 1.5, 2.4], theta_bounds=((0,1),(0,10),(0,5)), spec_bounds=(5,101), likelihood='Norm'):\n",
    "\n",
    "    #Access the global data we loaded\n",
    "    global N_meas, tlive_PuBe, g4, cap, Y\n",
    "    \n",
    "    ############\n",
    "    #Set some local variables\n",
    "    F_NR=None\n",
    "    scale_g4=None\n",
    "    scale_ng=None\n",
    "    NR=None\n",
    "    ER=None\n",
    "    NG=None\n",
    "    \n",
    "    if model=='Lind':\n",
    "        #Lindhard\n",
    "        Y.model=model\n",
    "        Y.pars=theta[:1]\n",
    "        F_NR=theta[2]\n",
    "        scale_g4=theta[1]\n",
    "        scale_ng=scale_g4\n",
    "\n",
    "    elif (model=='Chav' or model=='Sor'):\n",
    "        #Chavarria or Sorensen with constant\n",
    "        Y.model=model\n",
    "        Y.pars=theta[:2]\n",
    "        F_NR=theta[3]\n",
    "        scale_g4=theta[2]\n",
    "        scale_ng=scale_g4\n",
    "\n",
    "    elif (model=='Damic'):\n",
    "        #Damic yield\n",
    "        Y.model=model\n",
    "        Y.pars=[]\n",
    "        F_NR=theta[1]\n",
    "        scale_g4=theta[0]\n",
    "        scale_ng=scale_g4\n",
    "\n",
    "    else:\n",
    "        print('Error: Yield model not defined.')\n",
    "        return None\n",
    "    \n",
    "    \n",
    "    #Calculate the (log)prior first since we may not need to calculate the likelihood\n",
    "    lp=lp_flat(theta, theta_bounds)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "        \n",
    "    \n",
    "    ##########\n",
    "    #Build the spectra\n",
    "    #NR,ER,NG=spec.buildSimSpectra_ee(Ebins=Ebins, Evec_nr=g4['NR']['E'], Evec_er=g4['ER']['E'], Evec_ng=cap['E'], dEvec_ng=cap['dE'], \n",
    "                                         #Yield=Y, F_NR=F_NR, scale_g4=scale_g4, scale_ng=scale_ng, doDetRes=True, seed=1)\n",
    "\n",
    "    #Avg spectra is more stable\n",
    "    NR,ER,NG=spec.buildAvgSimSpectra_ee(Ebins=Ebins, Evec_nr=g4['NR']['E'], Evec_er=g4['ER']['E'], Evec_ng=cap['E'], dEvec_ng=cap['dE'],\n",
    "                                        Yield=Y, F_NR=F_NR, scale_g4=scale_g4, scale_ng=scale_ng, doDetRes=True)\n",
    "\n",
    "\n",
    "    #Total counts for PuBe live time\n",
    "    #Uncertainty will be sqrt(N)\n",
    "    N_pred = (NR/g4['NR']['tlive'] + ER/g4['ER']['tlive'] + NG/cap['tlive'])*tlive_PuBe\n",
    "\n",
    "    ##########\n",
    "    #Calculate the log probability = log prior + log likelihood\n",
    "    ll=None\n",
    "    \n",
    "    if likelihood=='Norm':\n",
    "        ll = ll_norm(N_meas[slice(*spec_bounds)],N_pred[slice(*spec_bounds)])\n",
    "    elif likelihood=='Pois':\n",
    "        ll = ll_pois(N_meas[slice(*spec_bounds)],N_pred[slice(*spec_bounds)])\n",
    "    else:\n",
    "        print('Error: Bad likelihood')\n",
    "        return None\n",
    "    \n",
    "    if not np.isfinite(ll):\n",
    "        return -np.inf\n",
    "    \n",
    "    return lp + ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emcee\n",
    "from multiprocessing import Pool\n",
    "\n",
    "#Lindhard fit\n",
    "# theta = k, sim_scale, F_NR\n",
    "labels_l = ['k', 'sim scale', 'F_{NR}']\n",
    "\n",
    "Y=Yield.Yield('Lind',[0.2])\n",
    "\n",
    "#Wrapper help\n",
    "def LindFit_helper(theta):\n",
    "    return calc_log_prob(model='Lind', theta=theta, theta_bounds=((0,1),(0,10),(0,5)),\n",
    "                         spec_bounds=(5,101), likelihood='Norm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2011/5000 [16:57:37<25:04:39, 30.20s/it]"
     ]
    }
   ],
   "source": [
    "nwalkers_l = 8\n",
    "ndim_l = 3\n",
    "nstep_l=5000\n",
    "guesses_l = np.array([0.18, 1.6, 3.8]) + 1e-3 * np.random.randn(nwalkers_l, ndim_l)\n",
    "\n",
    "with Pool(processes=20) as pool: #Can fail depending on current memory usage of other processes...\n",
    "    sampler_l = emcee.EnsembleSampler(nwalkers_l, ndim_l, LindFit_helper, pool=pool)\n",
    "    sampler_l.run_mcmc(guesses_l, nstep_l, progress=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save this work\n",
    "import pickle as pkl\n",
    "import os\n",
    "\n",
    "saveMCMC=True\n",
    "\n",
    "if saveMCMC:\n",
    "    ifile = 0\n",
    "    fname='data/mcmc_Lind_{0}walk_{1}step_v{2}.pkl'.format(nwalkers_l,nstep_l,ifile+1)\n",
    "    while os.path.exists(fname):\n",
    "        ifile += 1\n",
    "        fname='data/mcmc_Lind_{0}walk_{1}step_v{2}.pkl'.format(nwalkers_l,nstep_l,ifile+1)\n",
    "        \n",
    "    print(fname)\n",
    "    saveFile = open(fname, 'wb')\n",
    "    pkl.dump(sampler_l,saveFile)\n",
    "    pkl.dump(guesses_l,saveFile)\n",
    "    saveFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at the chain of parameter values\n",
    "fig, axes = plt.subplots(ndim_l, figsize=(10, 7), sharex=True)\n",
    "samples_l = sampler_l.get_chain()\n",
    "for i in range(ndim_l):\n",
    "    ax = axes[i]\n",
    "    ax.plot(samples_l[:, :, i], \"k\", alpha=0.3)\n",
    "    ax.set_xlim(0, len(samples_l))\n",
    "    #ax.set_ylim(0, 5)\n",
    "    ax.set_ylabel(labels_l[i])\n",
    "    ax.yaxis.set_label_coords(-0.1, 0.5)\n",
    "\n",
    "axes[-1].set_xlabel(\"step number\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the sample autocorrelation time\n",
    "tau_l=sampler_l.get_autocorr_time()\n",
    "print(tau_l)\n",
    "avgtau_l=round(np.average(tau_l))\n",
    "print(avgtau_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Discard a few times tau as burn-in and thin by tau/2\n",
    "avgtau_l=50\n",
    "flat_samples_l = sampler_l.get_chain(discard=int(2.*avgtau_l), thin=int(round(avgtau_l/2.)), flat=True)\n",
    "#flat_samples_l = sampler.get_chain(discard=40, flat=True)\n",
    "print(flat_samples_l.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import corner\n",
    "\n",
    "fig = corner.corner(\n",
    "    flat_samples_l, labels=labels_l\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Math\n",
    "\n",
    "for i in range(ndim_l):\n",
    "    mcmc = np.percentile(flat_samples_l[:, i], [16, 50, 84])\n",
    "    q = np.diff(mcmc)\n",
    "    txt = \"\\mathrm{{{3}}} = {0:.3f}_{{-{1:.3f}}}^{{+{2:.3f}}}\"\n",
    "    txt = txt.format(mcmc[1], q[0], q[1], labels_l[i])\n",
    "    display(Math(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the best fit results\n",
    "Y.model='Lind'\n",
    "#Lindhard\n",
    "Y.pars=resL.x[:1]\n",
    "F_NR=resL.x[2]\n",
    "scale_g4=resL.x[1]\n",
    "scale_ng=scale_g4\n",
    "\n",
    "NR,ER,NG=spec.buildSimSpectra_ee(Ebins=Ebins, Evec_nr=g4['NR']['E'], Evec_er=g4['ER']['E'], Evec_ng=cap['E'], dEvec_ng=cap['dE'],\n",
    "                                 Yield=Y, F_NR=F_NR, scale_g4=scale_g4, scale_ng=scale_ng, doDetRes=True, seed=1)\n",
    "spec.plotSpectra(E_bins=Ebins, N_nr=NR/g4['NR']['tlive'], N_er=ER/g4['ER']['tlive'], \n",
    "                 N_ng=NG/cap['tlive'], N_meas=R_meas, dN_meas=dR_meas , \n",
    "                 yrange=(0,1e-2), thresh=Ebins[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import fsolve\n",
    "def ERtoNR(ER,Y,V,eps):\n",
    "    func = lambda NR : NR-ER*(1+V/eps)/(1+Y.calc(NR)*V/eps)\n",
    "    NR_guess = ER\n",
    "    return fsolve(func, NR_guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot best fit yield\n",
    "fig, ax = plt.subplots(1,1)\n",
    "\n",
    "Y.model='Lind'\n",
    "Y.pars=resL.x[:1]\n",
    "\n",
    "Er_low_l=ERtoNR(Ebins[5],Y,V,eps)[0]\n",
    "Er_high_l=ERtoNR(Ebins[101],Y,V,eps)[0]\n",
    "\n",
    "E_l=np.linspace(Er_low_l,Er_high_l,1000)\n",
    "\n",
    "\n",
    "Ymean=Y.calc(E_l)\n",
    "Y.pars=resL.x[:1]+3*resL.err[:1]\n",
    "Yup=Y.calc(E_l)\n",
    "Y.pars=resL.x[:1]-3*resL.err[:1]\n",
    "Ydown=Y.calc(E_l)\n",
    "\n",
    "ax.plot(E_l, Ymean,label='Best Fit Lindhard')\n",
    "ax.fill_between(E_l,Ydown,Yup,alpha=0.5)\n",
    "\n",
    "#ax.axvline(Ebins[5]/Y.calc(Ebins[5]),color='k',linestyle='--',label=\"Noise Threshold\")\n",
    "#ax.axvline(Ebins[101]/Y.calc(Ebins[5]),color='r',linestyle='--',label=\"Upper Analysis Threshold\")\n",
    "\n",
    "ax.set_xlabel('Er')\n",
    "ax.set_ylabel('Y')\n",
    "#ax.set_ylim(0.1,0.4)\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_l = ['k', 'sim_scale', 'F_NR']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta=[0.1, 1.6, 2.4]\n",
    "theta_bounds=((0,1),(0,10),(0,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lp_flat(theta,theta_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nr_fano] *",
   "language": "python",
   "name": "conda-env-nr_fano-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
